cnms = colnames(a)[desired_cols]
nc = length(desired_cols)
nms = c()
d = matrix(nrow=nc,ncol=nc,data=NA)
for (i in 1:(nc-1)) {
print(i)
for (j in (i+1):nc) {
v1 = a[, desired_cols[i]]
v2 = a[, desired_cols[j]]
b = table(v1,v2)
b = b[2:dim(b)[1],2:dim(b)[2]]
#b = b/sum(b)
#chi = chisq.test(b)
#d[i,j] = chi$p.value
#d[j,i] = chi$p.value
nms=c(nms,paste(cnms[i],cnms[j],sep='-'))
if (i==1) x = list(b)
else x = append(x,list(b))
}
}
x
nms
x
a[1,]
a[1,]
hist(a$latitude,100)
plot(a$latitude,a$longitude)
plot(a$longitude,a$latitude)
abs(a$latitude/10)*10
abs(round(a$latitude/10))*10
a[1,]
colnames(a)
which(colnames(a)=='X41A.Distance.Contrasts.in.Demonstratives')
table(abs(round(a$latitude/10))*10,a[,49]
)
table((round(a$latitude/10))*10,a[,49])
setwd('~/Sites/Dropbox/wals-R-modeling/wals')
a = read.csv('language.csv',sep=',',header=T)
a[1,]
cnms = colnames(a)[desired_cols]
desired_cols=c(91,93,94)
cnms = colnames(a)[desired_cols]
cnms
a$X86A.Order.of.Genitive.and.Noun
nc = length(desired_cols)
nms = c()
d = matrix(nrow=nc,ncol=nc,data=NA)
for (i in 1:(nc-1)) {
print(i)
for (j in (i+1):nc) {
v1 = a[, desired_cols[i]]
v2 = a[, desired_cols[j]]
b = table(v1,v2)
b = b[2:dim(b)[1],2:dim(b)[2]]
#b = b/sum(b)
#chi = chisq.test(b)
#d[i,j] = chi$p.value
#d[j,i] = chi$p.value
nms=c(nms,paste(cnms[i],cnms[j],sep='-'))
if (i==1) x = list(b)
else x = append(x,list(b))
}
}
x
nc
nc = length(desired_cols)
nms = c()
d = matrix(nrow=nc,ncol=nc,data=NA)
for (i in 1:(nc-1)) {
print(i)
for (j in (i+1):nc) {
v1 = a[, desired_cols[i]]
v2 = a[, desired_cols[j]]
b = table(v1,v2)
b = b[2:dim(b)[1],2:dim(b)[2]]
#b = b/sum(b)
#chi = chisq.test(b)
#d[i,j] = chi$p.value
#d[j,i] = chi$p.value
nms=c(nms,paste(cnms[i],cnms[j],sep='-'))
if (i==1 & j==2) x = list(b)
else x = append(x,list(b))
}
}
x
x[1]
x[2]
x[3]
F = matrix(x[1])
F
F = data.frame(x[1])
F
sum(F)
F = data.frame(x[1])/sum(F)
F
O = matrix(runif(3*5),rows=3,cols=5)
O = matrix(runif(3*5),rows=3,col=5)
O = matrix(runif(3*5),row=3,col=5)
O = matrix(runif(3*5),nrow=3,ncol=5)
O
O = O/sum(O)
O
F-O
O-F
O = O+LR*dO
LR = .1
dO = O-F
O = O+LR*dO
O
for (i in 1:100) {
O = O+LR*dO
}
O
LR = .001
for (i in 1:100) {
dO = O-F
O = O+LR*dO
}
O
F
LR = .00001
for (i in 1:1000) {
dO = O-F
O = O+LR*dO
}
O
dO
for (i in 1:999) {
dO = O-F
O = O+LR*dO
}
O
dO
F
F = data.frame(x[1])/sum(F)
O = matrix(runif(3*5),nrow=3,ncol=5)
O = O/sum(O)
LR = .00001
for (i in 1:999) {
dO = O-F
O = O+LR*dO
}
O
dO
F = data.frame(x[1])/sum(F)
O = matrix(runif(3*5),nrow=3,ncol=5)
O = O/sum(O)
LR = .00001
for (i in 1:999) {
dO = O-F
O = O-LR*dO
}
F = data.frame(x[1])/sum(F)
O = matrix(runif(3*5),nrow=3,ncol=5)
O = O/sum(O)
LR = .00001
for (i in 1:999) {
dO = F-O
O = O+LR*dO
}
O
dO
F
F = data.frame(x[1])/sum(F)
O = matrix(runif(3*5),nrow=3,ncol=5)
O = O/sum(O)
LR = .00001
for (i in 1:999) {
dO = F-O
O = O+LR*dO
}
F = data.frame(x[1])/sum(x[1])
O = matrix(runif(3*5),nrow=3,ncol=5)
O = O/sum(O)
LR = .00001
for (i in 1:999) {
dO = F-O
O = O+LR*dO
}
O
F
F = data.frame(x[1])/sum(x[1])
O = matrix(runif(3*5),nrow=3,ncol=5)
O = O/sum(O)
LR = .00001
for (i in 1:1000) {
dO = F-O
O = O+LR*dO
}
O
F
F = data.frame(x[1])/sum(x[1])
O = matrix(runif(3*5),nrow=3,ncol=5)
O = O/sum(O)
LR = .001
for (i in 1:1000) {
dO = F-O
O = O+LR*dO
}
sim(x[1])
sum(x[1])
x[1]
F = data.frame(x[1])
F = F/sum(F)
O = matrix(runif(3*5),nrow=3,ncol=5)
O = O/sum(O)
LR = .001
for (i in 1:1000) {
dO = F-O
O = O+LR*dO
}
O
F
setwd('~/Sites/Dropbox/wals-R-modeling/wals')
a = read.csv('language.csv',sep=',',header=T)
desired_cols = c(57,82,83,86)
desired_cols=c(91,93,94)
cnms = colnames(a)[desired_cols]
cnms
a[1,]
nc = length(desired_cols)
nms = c()
d = matrix(nrow=nc,ncol=nc,data=NA)
for (i in 1:(nc-1)) {
print(i)
for (j in (i+1):nc) {
v1 = a[, desired_cols[i]]
v2 = a[, desired_cols[j]]
b = table(v1,v2)
b = b[2:dim(b)[1],2:dim(b)[2]]
#b = b/sum(b)
#chi = chisq.test(b)
#d[i,j] = chi$p.value
#d[j,i] = chi$p.value
nms=c(nms,paste(cnms[i],cnms[j],sep='-'))
if (i==1 & j==2) x = list(b)
else x = append(x,list(b))
}
}
F = data.frame(x[1])
F = F/sum(F)
O = matrix(runif(3*5),nrow=3,ncol=5)
O = O/sum(O)
LR = .001
for (i in 1:1000) {
dO = F-O
O = O+LR*dO
}
O
colnames(a)
install.packages("plotly")
for (i in 1:dim(a)[2]) {
for (j in 1:dim(a)[2]) {
print(c(i,j))
v1 = a[, i]
v2 = a[, desired_cols[j]]
b = table(v1,v2)
chi = chisq.test(b)
}
}
for (i in 1:dim(a)[2]) {
for (j in 1:dim(a)[2]) {
print(c(i,j))
v1 = a[, i]
v2 = a[, j]
b = table(v1,v2)
chi = chisq.test(b)
}
}
chi
str(chi)
chi$p.value
results = data.frame(0,nrow=200,ncol=200)
dim(results)
results
results = matrix(0,nrows=200,ncols=200)
results = matrix(0,nrow=200,ncol=200)
dim(results)
results
results = matrix(0,nrow=200,ncol=200)
for (i in 1:dim(a)[2]) {
for (j in 1:dim(a)[2]) {
print(c(i,j))
v1 = a[, i]
v2 = a[, j]
b = table(v1,v2)
chi = chisq.test(b)
results[i,j] = chi$p.value
}
}
warnings()
results
indcs = which(results<.0001,arr.ind=T)
indcs
library(igraph)
cnms = colnames(a)
indcs2 = cbind(cnms[indcs[,1]],cnms[indcs[,2]])
indcs2
dim(indcs2)
cnms = colnames(a)
indcs = which(results<.0001,arr.ind=T)
library(igraph)
indcs2 = cbind(cnms[indcs[,1]],cnms[indcs[,2]])
edges = indcs2
alphabetorder = function(x) { # alphabetize to uniqify
s = edges[x,]
edges[x,] <<- edges[x,order(s)]
return()
}
result = sapply(1:dim(edges)[1],alphabetorder)
edges = unique(edges)
net = graph.data.frame(edges,directed=F)
plot(net)
edges
net = graph.data.frame(edges,directed=F)
edges[1,]
edges[2,]
edges[3,]
edges[4,]
edges[5,]
edges[6,]
edges[8,]
edges[9,]
a[1,]
cnms
results = matrix(0,nrow=200,ncol=200)
for (i in 7:dim(a)[2]) {
for (j in 1:dim(a)[2]) {
print(c(i,j))
v1 = a[, i]
v2 = a[, j]
b = table(v1,v2)
chi = chisq.test(b)
results[i,j] = chi$p.value
}
}
edges[8,]
cnms = colnames(a)
indcs = which(results<.0001,arr.ind=T)
library(igraph)
indcs2 = cbind(cnms[indcs[,1]],cnms[indcs[,2]])
edges = indcs2
dim(edges)
edges[1,]
edges[2,]
edges[3,]
indcs2 = cbind(cnms[indcs[,1]]+6,cnms[indcs[,2]]+6)
edges = indcs2
indcs2 = cbind(cnms[indcs[,1]+6],cnms[indcs[,2]+6])
edges = indcs2
edges[3,]
edges[2,]
edges[10,]
alphabetorder = function(x) { # alphabetize to uniqify
s = edges[x,]
edges[x,] <<- edges[x,order(s)]
return()
}
result = sapply(1:dim(edges)[1],alphabetorder)
edges = unique(edges)
dim(edges)
net = graph.data.frame(edges,directed=F)
edges[1,]
edges[4,]
as.character(edges)
net = graph.data.frame(as.character(edges),directed=F)
edges[1:10,]
net = graph.data.frame(edges,directed=F)
net = graph.data.frame(edges[1:1000,],directed=F)
net = graph.data.frame(edges[1:10,],directed=F)
net = graph.data.frame(edges[1:1000,],directed=F)
indcs2 = cbind(as.character(cnms[indcs[,1]+6]),as.character(cnms[indcs[,2]+6]))
edges = indcs2
alphabetorder = function(x) { # alphabetize to uniqify
s = edges[x,]
edges[x,] <<- edges[x,order(s)]
return()
}
result = sapply(1:dim(edges)[1],alphabetorder)
edges = unique(edges)
net = graph.data.frame(edges[1:1000,],directed=F)
net = graph.data.frame(edges,directed=F)
unique(edges[,1])
cnms
unique(edges[,1])
is.na(edges[,1])
sum(is.na(edges[,1]))
edges(is.na(edges[,1])
)
edges[is.na(edges[,1],]
edges[is.na(edges[,1]),]
edges[length(edges),]
edges[dim(edges)[1],]
edges = edges[1:(dim(edges)[1]-1),]
net = graph.data.frame(edges,directed=F)
edges[dim(edges)[1],]
edges = edges[!is.na(edges[,1]),]
edges = edges[!is.na(edges[,2]),]
net = graph.data.frame(edges,directed=F)
edges
net = graph.data.frame(edges,directed=F)
dim(edges)
edges[1:10,]
net = graph.data.frame(edges[1:10,],directed=F)
library(igraph)
library(tm)
library(ff)
setwd('~/Sites/Dropbox/social-cbl')
sents = readChar('sents.txt', file.info('sents.txt')$size)
sents = paste('. ',sents,sep='') # att utterance boundary in slot 1
sents = substr(sents,1,nchar(sents)-1) # get rid of trailing space
word.seq = unlist(strsplit(sents," "))
words = sort(unique(word.seq))
### reverse bigram transition for local chunks
btp.mat = matrix(0,nrow=length(words),ncol=length(words))
b.bis = data.frame(w1=word.seq[length(word.seq):2],w2=word.seq[(length(word.seq)-1):1],stringsAsFactors=F)
b.bis.cols = t(apply(b.bis,1,function (x) {
return(c(which(x[1]==words),which(x[2]==words)))
}))
apply(b.bis.cols,1,function (x) {
btp.mat[x[1],x[2]]<<-btp.mat[x[1],x[2]]+1;return()
})
btp.mat = t(apply(btp.mat,1,function (x) {
return(x/sum(x));
}))
big.chunks = which(btp.mat>mean(btp.mat[btp.mat>0]),arr.ind=T)
big.chunks = cbind(words[big.chunks[,2]],words[big.chunks[,1]])
### semanto-chunks through some k window size
semantico.func = function(words,word.seq,k) {
cooc.mat = matrix(0,nrow=length(words),ncol=length(words))
b.code = unlist(lapply(word.seq,function (x) {
return(which(x==words))
}))
windows = embed(b.code,k)
result = apply(windows,1,function (x) {
inds = expand.grid(x,x)
inds = inds[inds[,1]!=inds[,2],]
inds = arrayIndex2vectorIndex(as.matrix(inds),dim(cooc.mat)) #ff function, similar to MATLAB ind2sub
cooc.mat[inds]<<-cooc.mat[inds]+1
return()
})
cooc.mat = t(apply(cooc.mat,1,function (x) {
return(x/sum(x));
}))
semantico.groups = which(cooc.mat>(mean(cooc.mat[cooc.mat>0])),arr.ind=T)
semantico.groups = cbind(words[semantico.groups[,2]],words[semantico.groups[,1]])
semantico.class = setClass("semantico.class",slots=c(semantico.groups="matrix",cooc.mat="matrix"))
return(semantico.class(semantico.groups=semantico.groups,cooc.mat=cooc.mat))
}
s = semantico.func(words,word.seq,k<-20)
plot(plot.semantico.groups(s@semantico.groups))
install.packages("ff")
library(tm)
library(ff)
setwd('~/Sites/Dropbox/social-cbl')
sents = readChar('sents.txt', file.info('sents.txt')$size)
sents = paste('. ',sents,sep='') # att utterance boundary in slot 1
sents = substr(sents,1,nchar(sents)-1) # get rid of trailing space
word.seq = unlist(strsplit(sents," "))
words = sort(unique(word.seq))
### reverse bigram transition for local chunks
btp.mat = matrix(0,nrow=length(words),ncol=length(words))
b.bis = data.frame(w1=word.seq[length(word.seq):2],w2=word.seq[(length(word.seq)-1):1],stringsAsFactors=F)
b.bis.cols = t(apply(b.bis,1,function (x) {
return(c(which(x[1]==words),which(x[2]==words)))
}))
apply(b.bis.cols,1,function (x) {
btp.mat[x[1],x[2]]<<-btp.mat[x[1],x[2]]+1;return()
})
btp.mat = t(apply(btp.mat,1,function (x) {
return(x/sum(x));
}))
big.chunks = which(btp.mat>mean(btp.mat[btp.mat>0]),arr.ind=T)
big.chunks = cbind(words[big.chunks[,2]],words[big.chunks[,1]])
### semanto-chunks through some k window size
semantico.func = function(words,word.seq,k) {
cooc.mat = matrix(0,nrow=length(words),ncol=length(words))
b.code = unlist(lapply(word.seq,function (x) {
return(which(x==words))
}))
windows = embed(b.code,k)
result = apply(windows,1,function (x) {
inds = expand.grid(x,x)
inds = inds[inds[,1]!=inds[,2],]
inds = arrayIndex2vectorIndex(as.matrix(inds),dim(cooc.mat)) #ff function, similar to MATLAB ind2sub
cooc.mat[inds]<<-cooc.mat[inds]+1
return()
})
cooc.mat = t(apply(cooc.mat,1,function (x) {
return(x/sum(x));
}))
semantico.groups = which(cooc.mat>(mean(cooc.mat[cooc.mat>0])),arr.ind=T)
semantico.groups = cbind(words[semantico.groups[,2]],words[semantico.groups[,1]])
semantico.class = setClass("semantico.class",slots=c(semantico.groups="matrix",cooc.mat="matrix"))
return(semantico.class(semantico.groups=semantico.groups,cooc.mat=cooc.mat))
}
s = semantico.func(words,word.seq,k<-20)
plot(plot.semantico.groups(s@semantico.groups))
s@semantico.groups
s@semantico.groups[1:10,]
str(s@semantico.groups)
str(edges)
semantico.groups = s@semantico.groups
edges = semantico.groups
alphabetorder = function(x) { # alphabetize to uniqify
s = edges[x,]
edges[x,] <<- edges[x,order(s)]
return()
}
result = sapply(1:dim(edges)[1],alphabetorder)
edges = unique(edges)
net = graph.data.frame(edges,directed=F)
